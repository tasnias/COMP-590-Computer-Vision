{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"mnist_pytorch.ipynb","provenance":[],"collapsed_sections":[]},"kernelspec":{"name":"python3","display_name":"Python 3"},"accelerator":"GPU"},"cells":[{"cell_type":"markdown","metadata":{"id":"QscbMmx0KhED","colab_type":"text"},"source":["Dataloader for MNIST dataset\n"]},{"cell_type":"code","metadata":{"id":"CkDbtD1tupoO","colab_type":"code","colab":{}},"source":["import torch\n","import torchvision\n","import torchvision.transforms as transforms\n","\n","class CifarLoader(object):\n","    \"\"\"docstring for CifarLoader\"\"\"\n","    def __init__(self):\n","        super(CifarLoader, self).__init__()\n","        transform = transforms.Compose(\n","\t\t    [\n","\t\t     # TODO: Add data augmentations here\n","\t\t     transforms.ToTensor()\n","\t\t     ])\n","        transform_test = transforms.Compose([\n","\t\t    transforms.ToTensor(),\n","\t\t])\n","  \n","        train_set = torchvision.datasets.MNIST('./', transform=transform, train=True, download=True)\n","        print(len(train_set))\n","        self.trainloader = torch.utils.data.DataLoader(train_set,\n","                                              batch_size=64,\n","                                              shuffle=True)\n","        test_set = torchvision.datasets.MNIST('./', transform=transform_test, train=False, download=True)\n","        self.testloader = torch.utils.data.DataLoader(test_set,\n","                                              batch_size=64,\n","                                              shuffle=False)    "],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"5XXjLP0vLfkd","colab_type":"text"},"source":["Network architecture class.\n","net = Net() will initialize a network. The architecture is defined in the forward() function.\n","Calling the network to perform one step of prediction is simply net(input), this will give input to the network and call the forward() function."]},{"cell_type":"code","metadata":{"id":"T-O4YyL84j-1","colab_type":"code","colab":{}},"source":["import torch\n","import torch.nn as nn\n","import torch.nn.functional as F\n","\n","\n","class Net(nn.Module):\n","\n","    def __init__(self):\n","        super(Net, self).__init__()\n","        # 1 input image channel, 6 output channels, 3x3 square convolution\n","        # kernel\n","        self.conv1 = nn.Conv2d(1, 6, 3)\n","        self.conv2 = nn.Conv2d(6, 16, 3)\n","        # an affine operation: y = Wx + b\n","        self.fc1 = nn.Linear(16 * 5 * 5, 120)  # 6*6 from image dimension\n","        self.fc2 = nn.Linear(120, 84)\n","        self.fc3 = nn.Linear(84, 10)\n","\n","    def forward(self, x):\n","        # Max pooling over a (2, 2) window\n","        x = F.max_pool2d(F.relu(self.conv1(x)), (2, 2))\n","        # If the size is a square you can only specify a single number\n","        x = F.max_pool2d(F.relu(self.conv2(x)), 2)\n","        x = x.view(-1, self.num_flat_features(x))\n","        x = F.relu(self.fc1(x))\n","        x = F.relu(self.fc2(x))\n","        x = self.fc3(x)\n","        output = F.log_softmax(x, dim=1)\n","        return output\n","\n","    def num_flat_features(self, x):\n","        size = x.size()[1:]  # all dimensions except the batch dimension\n","        num_features = 1\n","        for s in size:\n","            num_features *= s\n","        return num_features\n"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"EocMJ8PeMmz_","colab_type":"text"},"source":["Training and testing function.\n","You need to filling in the missing steps in this function"]},{"cell_type":"code","metadata":{"id":"sihZC7qBOViS","colab_type":"code","colab":{}},"source":["def train(net, dataloader, optimizer, criterion, epoch):\n","    running_loss = 0.0\n","    total_loss = 0.0\n","\n","    for i, data in enumerate(dataloader.trainloader, 0):\n","        # get the inputs\n","        inputs, labels = data\n","        # zero the parameter gradients\n","        optimizer.zero_grad()\n","\n","        # forward + compute loss + backward + update weights\n","        # 1. forward pass of network\n","        output = net(inputs)\n","        # 2. Compute loss using criterion function\n","        loss = criterion(output, labels)\n","        # 3. compute gradient with respect to loss use backpropagation\n","        loss.backward()\n","        # 4. update network weights using optimizer\n","        optimizer.step()\n","\n","        # print statistics\n","        running_loss += loss.item()\n","        total_loss += loss.item()\n","        if (i + 1) % 200 == 0:    # print every 2000 mini-batches\n","            print('[%d, %5d] loss: %.3f' %\n","                  (epoch + 1, i + 1, running_loss / 200))\n","            running_loss = 0.0\n","\n","    print('Final Summary:   loss: %.3f' %\n","          (total_loss / i))\n","\n","\n","def test(net, dataloader, tag=''):\n","    correct = 0\n","    total = 0\n","    if tag == 'Train':\n","        dataTestLoader = dataloader.trainloader\n","    else:\n","        dataTestLoader = dataloader.testloader\n","    with torch.no_grad():\n","        for data in dataTestLoader:\n","            images, labels = data\n","            # 1. forward pass of network\n","            output = net(images)\n","            # 2. Prediction is the maximum label in the output\n","            prediction = output.data.max(1)[1]\n","            # 3. Compare with the groundtruth label and count the number of \n","            #    correct predictions\n","            correct += prediction.eq(labels.data).sum()\n","            total += len(labels.data)\n","\n","    print('%s Accuracy of the network: %d %%' % (tag,\n","        100. * correct / total))\n"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"JgNEcqMJgBWp","colab_type":"text"},"source":["Training and testing network"]},{"cell_type":"code","metadata":{"id":"ANbjG4haHlN5","colab_type":"code","outputId":"2549ab21-5ad0-4b12-e87c-564ecd6b36ba","executionInfo":{"status":"ok","timestamp":1586300640377,"user_tz":240,"elapsed":203304,"user":{"displayName":"Tasnia Sarwar","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GiWOINw3dxYk9DlYbDP40TqmeP4vXfTAPGLWswl0Q=s64","userId":"01846151153486763757"}},"colab":{"base_uri":"https://localhost:8080/","height":1000}},"source":["import torch.optim as optim\n","\n","epochs = 10  # \n","net = Net()\n","print(net)\n","\n","# create your optimizer\n","optimizer = optim.SGD(net.parameters(), lr=0.01)\n","criterion = nn.NLLLoss()\n","\n","# Create dataloader\n","cifarLoader = CifarLoader()\n","\n","#train(net, cifarLoader, optimizer, criterion, 1)\n","for epoch in range(epochs):  # loop over the dataset multiple times\n","    print('EPOCH', epoch + 1)\n","    train(net, cifarLoader, optimizer, criterion, epoch)\n","    if epoch % 1 == 0: # Comment out this part if you want a faster training\n","        test(net, cifarLoader, 'Train')\n","        test(net, cifarLoader, 'Test')"],"execution_count":18,"outputs":[{"output_type":"stream","text":["Net(\n","  (conv1): Conv2d(1, 6, kernel_size=(3, 3), stride=(1, 1))\n","  (conv2): Conv2d(6, 16, kernel_size=(3, 3), stride=(1, 1))\n","  (fc1): Linear(in_features=400, out_features=120, bias=True)\n","  (fc2): Linear(in_features=120, out_features=84, bias=True)\n","  (fc3): Linear(in_features=84, out_features=10, bias=True)\n",")\n","60000\n","EPOCH 1\n","[1,   200] loss: 2.299\n","[1,   400] loss: 2.286\n","[1,   600] loss: 2.259\n","[1,   800] loss: 2.107\n","Final Summary:   loss: 2.111\n","Train Accuracy of the network: 70 %\n","Test Accuracy of the network: 71 %\n","EPOCH 2\n","[2,   200] loss: 0.706\n","[2,   400] loss: 0.516\n","[2,   600] loss: 0.444\n","[2,   800] loss: 0.391\n","Final Summary:   loss: 0.494\n","Train Accuracy of the network: 87 %\n","Test Accuracy of the network: 87 %\n","EPOCH 3\n","[3,   200] loss: 0.338\n","[3,   400] loss: 0.317\n","[3,   600] loss: 0.293\n","[3,   800] loss: 0.275\n","Final Summary:   loss: 0.298\n","Train Accuracy of the network: 92 %\n","Test Accuracy of the network: 93 %\n","EPOCH 4\n","[4,   200] loss: 0.242\n","[4,   400] loss: 0.229\n","[4,   600] loss: 0.210\n","[4,   800] loss: 0.222\n","Final Summary:   loss: 0.222\n","Train Accuracy of the network: 94 %\n","Test Accuracy of the network: 94 %\n","EPOCH 5\n","[5,   200] loss: 0.194\n","[5,   400] loss: 0.186\n","[5,   600] loss: 0.157\n","[5,   800] loss: 0.170\n","Final Summary:   loss: 0.175\n","Train Accuracy of the network: 94 %\n","Test Accuracy of the network: 95 %\n","EPOCH 6\n","[6,   200] loss: 0.144\n","[6,   400] loss: 0.148\n","[6,   600] loss: 0.144\n","[6,   800] loss: 0.142\n","Final Summary:   loss: 0.144\n","Train Accuracy of the network: 96 %\n","Test Accuracy of the network: 96 %\n","EPOCH 7\n","[7,   200] loss: 0.126\n","[7,   400] loss: 0.134\n","[7,   600] loss: 0.118\n","[7,   800] loss: 0.118\n","Final Summary:   loss: 0.123\n","Train Accuracy of the network: 95 %\n","Test Accuracy of the network: 95 %\n","EPOCH 8\n","[8,   200] loss: 0.107\n","[8,   400] loss: 0.108\n","[8,   600] loss: 0.107\n","[8,   800] loss: 0.107\n","Final Summary:   loss: 0.108\n","Train Accuracy of the network: 97 %\n","Test Accuracy of the network: 96 %\n","EPOCH 9\n","[9,   200] loss: 0.106\n","[9,   400] loss: 0.091\n","[9,   600] loss: 0.103\n","[9,   800] loss: 0.095\n","Final Summary:   loss: 0.097\n","Train Accuracy of the network: 97 %\n","Test Accuracy of the network: 97 %\n","EPOCH 10\n","[10,   200] loss: 0.091\n","[10,   400] loss: 0.093\n","[10,   600] loss: 0.085\n","[10,   800] loss: 0.086\n","Final Summary:   loss: 0.088\n","Train Accuracy of the network: 97 %\n","Test Accuracy of the network: 97 %\n"],"name":"stdout"}]}]}